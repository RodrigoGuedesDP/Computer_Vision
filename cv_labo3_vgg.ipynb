{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoGuedesDP/Computer_Vision/blob/main/cv_labo3_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Computer Vision -  Clasificación de expresiones faciales con VGG16**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   En este laboratorio se utilizor el modelo VGG16 pre-entrenado para construir un clasificador con estos datos y evaluar su rendimiento. Para ello se utilizará un dataset público llamado \"FER-2013\".\n",
        "**Autores:**  \n",
        "\n",
        "Nieto Espinoza, Brajan E.  \n",
        "[brajan.nieto@utec.edu.pe](mailto:brajan.nieto@utec.edu.pe)\n",
        "\n",
        "Guedes del Pozo,  Rodrigo F.  \n",
        "[rodrigo.guedes.d@utec.edu.pe](mailto:rodrigo.guedes.d@utec.edu.pe)\n",
        "\n",
        "<img src=\"https://pregrado.utec.edu.pe/sites/default/files/logo-utec-h_0_0.svg\" width=\"190\" alt=\"Logo UTEC\" loading=\"lazy\" typeof=\"foaf:Image\">      \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "izBcHpE6jDJZ"
      },
      "id": "izBcHpE6jDJZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 03: Claisifcacion de Emociones con VGG16"
      ],
      "metadata": {
        "id": "VcOTXhPPnbP8"
      },
      "id": "VcOTXhPPnbP8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e97d49d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e97d49d",
        "outputId": "1c6a0925-08a4-4296-a2d8-91351dbe5844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [1, 1000]                 --\n",
              "├─Sequential: 1-1                        [1, 512, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n",
              "│    └─ReLU: 2-2                         [1, 64, 224, 224]         --\n",
              "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         36,928\n",
              "│    └─ReLU: 2-4                         [1, 64, 224, 224]         --\n",
              "│    └─MaxPool2d: 2-5                    [1, 64, 112, 112]         --\n",
              "│    └─Conv2d: 2-6                       [1, 128, 112, 112]        73,856\n",
              "│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n",
              "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        147,584\n",
              "│    └─ReLU: 2-9                         [1, 128, 112, 112]        --\n",
              "│    └─MaxPool2d: 2-10                   [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          295,168\n",
              "│    └─ReLU: 2-12                        [1, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-14                        [1, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-16                        [1, 256, 56, 56]          --\n",
              "│    └─MaxPool2d: 2-17                   [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
              "│    └─ReLU: 2-19                        [1, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-21                        [1, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-23                        [1, 512, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-24                   [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-26                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-28                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-30                        [1, 512, 14, 14]          --\n",
              "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            --\n",
              "├─Sequential: 1-3                        [1, 1000]                 --\n",
              "│    └─Linear: 2-32                      [1, 4096]                 102,764,544\n",
              "│    └─ReLU: 2-33                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-34                     [1, 4096]                 --\n",
              "│    └─Linear: 2-35                      [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-36                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-37                     [1, 4096]                 --\n",
              "│    └─Linear: 2-38                      [1, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 138,357,544\n",
              "Trainable params: 138,357,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 15.48\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 108.45\n",
              "Params size (MB): 553.43\n",
              "Estimated Total Size (MB): 662.49\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "%pip install -q torch torchvision torchinfo scikit-learn matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuración de parámetros y dispositivo\n"
      ],
      "metadata": {
        "id": "mcyciVBTnkgv"
      },
      "id": "mcyciVBTnkgv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Dispositivo utilizado: {device}')\n",
        "\n",
        "# Parámetros\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 5\n",
        "NUM_CLASSES = 7  # 7 emociones: angry, disgust, fear, happy, neutral, sad, surprise\n",
        "LEARNING_RATE = 0.001\n"
      ],
      "metadata": {
        "id": "jOy7wEXxnlTN"
      },
      "id": "jOy7wEXxnlTN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transformaciones para VGG16\n",
        "\n",
        "VGG16 requiere imágenes de 224×224 píxeles normalizadas con valores específicos. Utilizamos las transformaciones estándar de ImageNet.\n"
      ],
      "metadata": {
        "id": "uD2aIHtUntO_"
      },
      "id": "uD2aIHtUntO_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f9c094b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f9c094b",
        "outputId": "956cfc46-b7fd-4d7b-8619-391541811817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de parámetros (sin pesos preentrenados): 138357544 ≈ 138.36 millones\n"
          ]
        }
      ],
      "source": [
        "# Transformaciones para entrenamiento: redimensionar, recortar y normalizar\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Transformaciones para validación/prueba: solo redimensionar y normalizar\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3acaf17d",
      "metadata": {
        "id": "3acaf17d"
      },
      "source": [
        "## 4. Cargar el dataset con ImageFolder\n",
        "\n",
        "El dataset FER-2013 ya está organizado en carpetas `train` y `test`, cada una con subcarpetas por emoción. Utilizamos `datasets.ImageFolder` para cargar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57807e76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57807e76",
        "outputId": "22b28db9-a34e-46f0-d0ef-449c51e22781"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [1, 1000]                 --\n",
              "├─Conv2d: 1-1                            [1, 64, 224, 224]         1,792\n",
              "├─ReLU: 1-2                              [1, 64, 224, 224]         --\n",
              "├─Conv2d: 1-3                            [1, 64, 224, 224]         36,928\n",
              "├─ReLU: 1-4                              [1, 64, 224, 224]         --\n",
              "├─MaxPool2d: 1-5                         [1, 64, 112, 112]         --\n",
              "├─Conv2d: 1-6                            [1, 128, 112, 112]        73,856\n",
              "├─ReLU: 1-7                              [1, 128, 112, 112]        --\n",
              "├─Conv2d: 1-8                            [1, 128, 112, 112]        147,584\n",
              "├─ReLU: 1-9                              [1, 128, 112, 112]        --\n",
              "├─MaxPool2d: 1-10                        [1, 128, 56, 56]          --\n",
              "├─Conv2d: 1-11                           [1, 256, 56, 56]          295,168\n",
              "├─ReLU: 1-12                             [1, 256, 56, 56]          --\n",
              "├─Conv2d: 1-13                           [1, 256, 56, 56]          590,080\n",
              "├─ReLU: 1-14                             [1, 256, 56, 56]          --\n",
              "├─Conv2d: 1-15                           [1, 256, 56, 56]          590,080\n",
              "├─ReLU: 1-16                             [1, 256, 56, 56]          --\n",
              "├─MaxPool2d: 1-17                        [1, 256, 28, 28]          --\n",
              "├─Conv2d: 1-18                           [1, 512, 28, 28]          1,180,160\n",
              "├─ReLU: 1-19                             [1, 512, 28, 28]          --\n",
              "├─Conv2d: 1-20                           [1, 512, 28, 28]          2,359,808\n",
              "├─ReLU: 1-21                             [1, 512, 28, 28]          --\n",
              "├─Conv2d: 1-22                           [1, 512, 28, 28]          2,359,808\n",
              "├─ReLU: 1-23                             [1, 512, 28, 28]          --\n",
              "├─MaxPool2d: 1-24                        [1, 512, 14, 14]          --\n",
              "├─Conv2d: 1-25                           [1, 512, 14, 14]          2,359,808\n",
              "├─ReLU: 1-26                             [1, 512, 14, 14]          --\n",
              "├─Conv2d: 1-27                           [1, 512, 14, 14]          2,359,808\n",
              "├─ReLU: 1-28                             [1, 512, 14, 14]          --\n",
              "├─Conv2d: 1-29                           [1, 512, 14, 14]          2,359,808\n",
              "├─ReLU: 1-30                             [1, 512, 14, 14]          --\n",
              "├─MaxPool2d: 1-31                        [1, 512, 7, 7]            --\n",
              "├─AdaptiveAvgPool2d: 1-32                [1, 512, 7, 7]            --\n",
              "├─Linear: 1-33                           [1, 4096]                 102,764,544\n",
              "├─ReLU: 1-34                             [1, 4096]                 --\n",
              "├─Dropout: 1-35                          [1, 4096]                 --\n",
              "├─Linear: 1-36                           [1, 4096]                 16,781,312\n",
              "├─ReLU: 1-37                             [1, 4096]                 --\n",
              "├─Dropout: 1-38                          [1, 4096]                 --\n",
              "├─Linear: 1-39                           [1, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 138,357,544\n",
              "Trainable params: 138,357,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 15.48\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 108.45\n",
              "Params size (MB): 553.43\n",
              "Estimated Total Size (MB): 662.49\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Cargar datasets\n",
        "train_dataset = datasets.ImageFolder(root='train', transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root='test', transform=test_transforms)\n",
        "\n",
        "# Crear DataLoaders\n",
        "# Nota: num_workers=0 en Windows para evitar problemas de multiprocessing\n",
        "import os\n",
        "num_workers = 0 if os.name == 'nt' else 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Mostrar información del dataset\n",
        "print(f'Número de clases: {len(train_dataset.classes)}')\n",
        "print(f'Clases: {train_dataset.classes}')\n",
        "print(f'Número de imágenes de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de imágenes de prueba: {len(test_dataset)}')\n",
        "print(f'Tamaño del batch: {BATCH_SIZE}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c02e818",
      "metadata": {
        "id": "7c02e818"
      },
      "source": [
        "## 5. Cargar VGG16 preentrenado y modificar la capa de salida\n",
        "\n",
        "Cargamos VGG16 con pesos preentrenados en ImageNet y reemplazamos la última capa completamente conectada para que tenga 7 salidas (una por cada emoción)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c09f8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9c09f8b",
        "outputId": "4619a64c-9d39-4a89-fdd5-3c49b8708733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:07<00:00, 77.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [1, 1000]                 --\n",
              "├─Sequential: 1-1                        [1, 512, 7, 7]            --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n",
              "│    └─ReLU: 2-2                         [1, 64, 224, 224]         --\n",
              "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         36,928\n",
              "│    └─ReLU: 2-4                         [1, 64, 224, 224]         --\n",
              "│    └─MaxPool2d: 2-5                    [1, 64, 112, 112]         --\n",
              "│    └─Conv2d: 2-6                       [1, 128, 112, 112]        73,856\n",
              "│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n",
              "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        147,584\n",
              "│    └─ReLU: 2-9                         [1, 128, 112, 112]        --\n",
              "│    └─MaxPool2d: 2-10                   [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          295,168\n",
              "│    └─ReLU: 2-12                        [1, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-14                        [1, 256, 56, 56]          --\n",
              "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          590,080\n",
              "│    └─ReLU: 2-16                        [1, 256, 56, 56]          --\n",
              "│    └─MaxPool2d: 2-17                   [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
              "│    └─ReLU: 2-19                        [1, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-21                        [1, 512, 28, 28]          --\n",
              "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          2,359,808\n",
              "│    └─ReLU: 2-23                        [1, 512, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-24                   [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-26                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-28                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          2,359,808\n",
              "│    └─ReLU: 2-30                        [1, 512, 14, 14]          --\n",
              "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            --\n",
              "├─Sequential: 1-3                        [1, 1000]                 --\n",
              "│    └─Linear: 2-32                      [1, 4096]                 102,764,544\n",
              "│    └─ReLU: 2-33                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-34                     [1, 4096]                 --\n",
              "│    └─Linear: 2-35                      [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-36                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-37                     [1, 4096]                 --\n",
              "│    └─Linear: 2-38                      [1, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 138,357,544\n",
              "Trainable params: 138,357,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 15.48\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 108.45\n",
              "Params size (MB): 553.43\n",
              "Estimated Total Size (MB): 662.49\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Cargar VGG16 preentrenado\n",
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Reemplazar la capa de salida (classifier[-1] es la última capa Linear)\n",
        "# VGG16 tiene 1000 clases por defecto, necesitamos 7\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_features, NUM_CLASSES)\n",
        "\n",
        "# Mover el modelo al dispositivo\n",
        "model = model.to(device)\n",
        "\n",
        "print('Modelo VGG16 cargado y modificado')\n",
        "print(f'Última capa reemplazada: {model.classifier[6]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57345cb6",
      "metadata": {
        "id": "57345cb6"
      },
      "source": [
        "## 6. Congelar las capas convolucionales\n",
        "\n",
        "Congelamos los parámetros de las capas convolucionales (features) para que no se actualicen durante el entrenamiento. Solo entrenaremos las capas completamente conectadas (classifier).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44afc53c",
      "metadata": {
        "id": "44afc53c"
      },
      "outputs": [],
      "source": [
        "# Congelar las capas convolucionales (features)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Descongelar las capas del clasificador\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verificar cuántos parámetros son entrenables\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'Parámetros entrenables: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)')\n",
        "print(f'Total de parámetros: {total_params:,}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Configurar función de pérdida y optimizador"
      ],
      "metadata": {
        "id": "e0W7pSJ1oUXo"
      },
      "id": "e0W7pSJ1oUXo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de pérdida\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizador (solo para los parámetros entrenables)\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f'Función de pérdida: {criterion}')\n",
        "print(f'Optimizador: {optimizer}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoRjQXv3qFcw",
        "outputId": "6e0d4096-827c-4066-fc06-1af60613a2cb"
      },
      "id": "QoRjQXv3qFcw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicción: lorikeet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Entrenamiento del modelo\n",
        "\n",
        "Entrenamos el modelo durante 5 épocas, registrando la pérdida y precisión en cada época.\n"
      ],
      "metadata": {
        "id": "XdHwl-9DoZwn"
      },
      "id": "XdHwl-9DoZwn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas para almacenar métricas\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "# Entrenamiento\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estadísticas\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Mostrar progreso cada 100 batches\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f'Época [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], '\n",
        "                  f'Pérdida: {loss.item():.4f}, Precisión: {100*correct/total:.2f}%')\n",
        "\n",
        "    # Métricas de la época\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f'Época [{epoch+1}/{NUM_EPOCHS}] completada - '\n",
        "          f'Pérdida promedio: {epoch_loss:.4f}, Precisión: {epoch_accuracy:.2f}%')\n",
        "    print('-' * 60)\n",
        "\n",
        "print('Entrenamiento completado!')\n"
      ],
      "metadata": {
        "id": "VVC9nKBJoaNJ"
      },
      "id": "VVC9nKBJoaNJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Evaluación del modelo en el conjunto de prueba\n",
        "\n",
        "Evaluamos el rendimiento del modelo en el conjunto de prueba y mostramos métricas detalladas.\n"
      ],
      "metadata": {
        "id": "NbgoBMnJoiiN"
      },
      "id": "NbgoBMnJoiiN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Guardar predicciones y etiquetas para métricas detalladas\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Métricas generales\n",
        "test_accuracy = 100 * correct / total\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "print('=' * 60)\n",
        "print('RESULTADOS EN EL CONJUNTO DE PRUEBA')\n",
        "print('=' * 60)\n",
        "print(f'Pérdida promedio: {avg_test_loss:.4f}')\n",
        "print(f'Precisión: {test_accuracy:.2f}%')\n",
        "print(f'Total de muestras: {total}')\n",
        "print(f'Predicciones correctas: {correct}')\n",
        "print('=' * 60)\n"
      ],
      "metadata": {
        "id": "U6xJj2JjojLc"
      },
      "id": "U6xJj2JjojLc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Métricas detalladas por clase\n",
        "\n",
        "Mostramos el reporte de clasificación y la matriz de confusión para analizar el rendimiento por cada emoción."
      ],
      "metadata": {
        "id": "npZ7APoSoprR"
      },
      "id": "npZ7APoSoprR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de clasificación\n",
        "print('\\nREPORTE DE CLASIFICACIÓN POR CLASE:')\n",
        "print('=' * 60)\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=train_dataset.classes,\n",
        "                          digits=4))\n",
        "print('=' * 60)\n"
      ],
      "metadata": {
        "id": "5najU9hTosI_"
      },
      "id": "5najU9hTosI_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=train_dataset.classes,\n",
        "            yticklabels=train_dataset.classes)\n",
        "plt.title('Matriz de Confusión - Clasificación de Emociones')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.xlabel('Etiqueta Predicha')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ume7edqdowpW"
      },
      "id": "ume7edqdowpW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráficas de entrenamiento\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Gráfica de pérdida\n",
        "ax1.plot(range(1, NUM_EPOCHS + 1), train_losses, 'b-o')\n",
        "ax1.set_xlabel('Época')\n",
        "ax1.set_ylabel('Pérdida')\n",
        "ax1.set_title('Pérdida de Entrenamiento')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Gráfica de precisión\n",
        "ax2.plot(range(1, NUM_EPOCHS + 1), train_accuracies, 'r-o')\n",
        "ax2.set_xlabel('Época')\n",
        "ax2.set_ylabel('Precisión (%)')\n",
        "ax2.set_title('Precisión de Entrenamiento')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tIOXeDkSo0pH"
      },
      "id": "tIOXeDkSo0pH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Análisis de resultados\n",
        "\n",
        "### Explicación de los resultados obtenidos:\n",
        "\n",
        "1. **Precisión general**: El modelo alcanzó una precisión del X% en el conjunto de prueba, lo que indica...\n",
        "\n",
        "2. **Rendimiento por clase**:\n",
        "   - Las emociones con mejor rendimiento son...\n",
        "   - Las emociones más difíciles de clasificar son...\n",
        "\n",
        "3. **Matriz de confusión**: La matriz muestra que el modelo confunde principalmente...\n",
        "\n",
        "4. **Transfer Learning**: Al usar VGG16 preentrenado y congelar las capas convolucionales, aprovechamos las características aprendidas en ImageNet, lo que permite un buen rendimiento incluso con pocas épocas de entrenamiento.\n",
        "\n",
        "5. **Limitaciones**:\n",
        "   - El dataset tiene desbalance de clases (disgust tiene menos muestras)\n",
        "   - 5 épocas pueden ser insuficientes para un ajuste fino completo\n",
        "   - Las imágenes son en escala de grises convertidas a RGB, lo que puede afectar el rendimiento\n"
      ],
      "metadata": {
        "id": "mpPgbSV3o6Xd"
      },
      "id": "mpPgbSV3o6Xd"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}